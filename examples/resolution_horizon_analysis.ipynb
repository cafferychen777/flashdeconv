{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution Horizon Analysis for Visium HD\n",
    "\n",
    "This notebook demonstrates how to perform **multi-resolution deconvolution** on Visium HD data using FlashDeconv.\n",
    "\n",
    "**Key concept**: The \"Resolution Horizon\" is the critical bin size below which single-cell-level spatial information is preserved. Above this threshold, cell type signals rapidly collapse due to spatial averaging.\n",
    "\n",
    "**What you'll learn**:\n",
    "1. How to run FlashDeconv at multiple resolutions (8-128 \u03bcm)\n",
    "2. How to identify the resolution horizon for your data\n",
    "3. How to determine the optimal resolution for each cell type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install\n",
    "# !pip install flashdeconv scanpy pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import entropy\n",
    "import time\n",
    "\n",
    "from flashdeconv import FlashDeconv\n",
    "\n",
    "# Publication-ready style\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.size': 9,\n",
    "    'axes.linewidth': 0.8,\n",
    "    'axes.labelsize': 10,\n",
    "    'axes.titlesize': 11,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.dpi': 150,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "This example uses the **Visium HD Mouse Small Intestine** dataset from 10x Genomics.\n",
    "\n",
    "**Spatial data**: https://www.10xgenomics.com/datasets/visium-hd-cytassist-gene-expression-libraries-of-mouse-intestine\n",
    "\n",
    "**Reference data**: [Haber et al., Nature 2017](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE92332) - Mouse intestinal epithelium scRNA-seq\n",
    "\n",
    "```bash\n",
    "# Download Visium HD data\n",
    "curl -O https://cf.10xgenomics.com/samples/spatial-exp/3.0.0/Visium_HD_Mouse_Small_Intestine/Visium_HD_Mouse_Small_Intestine_binned_outputs.tar.gz\n",
    "tar -xzf Visium_HD_Mouse_Small_Intestine_binned_outputs.tar.gz\n",
    "\n",
    "# Reference data: download from GEO GSE92332 or use pre-processed version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURE YOUR DATA PATHS HERE ===\n",
    "VISIUM_HD_DIR = Path(\"./Visium_HD_Mouse_Small_Intestine_binned_outputs\")\n",
    "REFERENCE_PATH = Path(\"./haber_intestine_matched.h5ad\")  # Your scRNA-seq reference\n",
    "CELL_TYPE_KEY = \"celltype\"  # Column name in reference.obs containing cell type labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Core Functions\n",
    "\n",
    "These functions handle data loading, binning, and multi-resolution analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_visium_hd(data_dir: Path, bin_size: str = \"016um\"):\n    \"\"\"\n    Load Visium HD data at specified resolution.\n    \n    Parameters\n    ----------\n    data_dir : Path\n        Path to Visium HD binned outputs directory\n    bin_size : str\n        One of '002um', '008um', '016um'\n    \n    Returns\n    -------\n    adata : AnnData\n        Spatial data with coordinates in .obsm['spatial']\n    \"\"\"\n    import pyarrow.parquet as pq\n    \n    bin_path = data_dir / f\"square_{bin_size}\"\n    adata = sc.read_10x_h5(bin_path / \"filtered_feature_bc_matrix.h5\")\n    adata.var_names_make_unique()\n    \n    # Load spatial coordinates\n    positions = pq.read_table(bin_path / \"spatial\" / \"tissue_positions.parquet\").to_pandas()\n    positions = positions.set_index(\"barcode\")\n    common = adata.obs_names.intersection(positions.index)\n    adata = adata[common].copy()\n    adata.obsm[\"spatial\"] = positions.loc[common, [\"pxl_col_in_fullres\", \"pxl_row_in_fullres\"]].values\n    \n    return adata\n\n\ndef aggregate_to_bin_size(adata, coords, target_um: int, original_um: int = 8):\n    \"\"\"\n    Aggregate spots to coarser bin size.\n    \n    Parameters\n    ----------\n    adata : AnnData\n        Fine-resolution spatial data\n    coords : ndarray\n        Spatial coordinates in pixels (n_spots, 2)\n    target_um : int\n        Target bin size in micrometers\n    original_um : int\n        Original bin size in micrometers\n    \n    Returns\n    -------\n    adata_agg : AnnData\n        Aggregated data\n    coords_agg : ndarray\n        Aggregated coordinates\n    \"\"\"\n    from scipy import sparse\n    from scipy.spatial import cKDTree\n    \n    scale_factor = target_um // original_um\n    \n    if scale_factor == 1:\n        return adata.copy(), coords.copy()\n    \n    # Estimate pixel spacing from nearest neighbor distances\n    sample_size = min(10000, len(coords))\n    tree = cKDTree(coords[:sample_size])\n    distances, _ = tree.query(coords[:sample_size], k=2)\n    pixel_spacing = np.median(distances[:, 1])\n    \n    # Grid size in pixels\n    grid_size = pixel_spacing * scale_factor\n    \n    # Assign spots to grid cells\n    min_coords = coords.min(axis=0)\n    grid_x = ((coords[:, 0] - min_coords[0]) / grid_size).astype(int)\n    grid_y = ((coords[:, 1] - min_coords[1]) / grid_size).astype(int)\n    grid_ids = np.array([f\"{x}_{y}\" for x, y in zip(grid_x, grid_y)])\n    \n    # Aggregate\n    unique_grids = np.unique(grid_ids)\n    grid_to_idx = {g: i for i, g in enumerate(unique_grids)}\n    \n    # Build aggregation matrix\n    row_indices = np.array([grid_to_idx[g] for g in grid_ids])\n    col_indices = np.arange(len(grid_ids))\n    \n    agg_matrix = sparse.csr_matrix(\n        (np.ones(len(grid_ids)), (row_indices, col_indices)),\n        shape=(len(unique_grids), len(grid_ids))\n    )\n    \n    # Sum counts\n    if sparse.issparse(adata.X):\n        new_X = agg_matrix @ adata.X\n    else:\n        new_X = agg_matrix @ adata.X\n    \n    # Compute centroid coordinates for each bin\n    coords_agg = np.zeros((len(unique_grids), 2))\n    for i, g in enumerate(unique_grids):\n        mask = grid_ids == g\n        coords_agg[i] = coords[mask].mean(axis=0)\n    \n    adata_agg = sc.AnnData(X=new_X, var=adata.var.copy())\n    adata_agg.obsm[\"spatial\"] = coords_agg\n    \n    return adata_agg, coords_agg"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiscale_analysis(adata_st, adata_ref, cell_type_key, \n",
    "                            bin_sizes=[8, 16, 32, 64, 128], base_um=8):\n",
    "    \"\"\"\n",
    "    Run FlashDeconv at multiple resolutions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata_st : AnnData\n",
    "        Spatial data at finest resolution\n",
    "    adata_ref : AnnData\n",
    "        Single-cell reference with cell type annotations\n",
    "    cell_type_key : str\n",
    "        Column in adata_ref.obs containing cell type labels\n",
    "    bin_sizes : list\n",
    "        List of bin sizes in micrometers\n",
    "    base_um : int\n",
    "        Base resolution of input data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        {bin_size: {'proportions': ndarray, 'n_spots': int, 'runtime': float}}\n",
    "    cell_types : list\n",
    "        Cell type names\n",
    "    \"\"\"\n",
    "    # Build signature matrix from reference\n",
    "    cell_types = sorted(adata_ref.obs[cell_type_key].unique())\n",
    "    \n",
    "    # Align genes\n",
    "    common_genes = adata_st.var_names.intersection(adata_ref.var_names)\n",
    "    print(f\"Common genes: {len(common_genes)}\")\n",
    "    \n",
    "    adata_st = adata_st[:, common_genes].copy()\n",
    "    adata_ref = adata_ref[:, common_genes].copy()\n",
    "    \n",
    "    # Build signature matrix (K x G)\n",
    "    X_ref = np.zeros((len(cell_types), len(common_genes)))\n",
    "    for i, ct in enumerate(cell_types):\n",
    "        mask = adata_ref.obs[cell_type_key] == ct\n",
    "        X_ref[i] = np.asarray(adata_ref[mask].X.mean(axis=0)).flatten()\n",
    "    \n",
    "    coords = adata_st.obsm[\"spatial\"]\n",
    "    results = {}\n",
    "    \n",
    "    for bin_size in bin_sizes:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {bin_size} \u03bcm resolution...\")\n",
    "        \n",
    "        # Aggregate if needed\n",
    "        adata_bin, coords_bin = aggregate_to_bin_size(\n",
    "            adata_st, coords, bin_size, base_um\n",
    "        )\n",
    "        print(f\"  Spots: {adata_bin.n_obs:,}\")\n",
    "        \n",
    "        # Get count matrix\n",
    "        if hasattr(adata_bin.X, 'toarray'):\n",
    "            Y = adata_bin.X.toarray()\n",
    "        else:\n",
    "            Y = np.asarray(adata_bin.X)\n",
    "        \n",
    "        # Run FlashDeconv\n",
    "        model = FlashDeconv(\n",
    "            sketch_dim=512,\n",
    "            lambda_spatial=5000,\n",
    "            n_hvg=2000,\n",
    "            n_markers_per_type=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        t0 = time.time()\n",
    "        props = model.fit_transform(Y, X_ref, coords_bin, cell_type_names=cell_types)\n",
    "        runtime = time.time() - t0\n",
    "        \n",
    "        print(f\"  Runtime: {runtime:.2f}s ({adata_bin.n_obs/runtime:,.0f} spots/sec)\")\n",
    "        \n",
    "        results[bin_size] = {\n",
    "            'proportions': props,\n",
    "            'coords': coords_bin,\n",
    "            'n_spots': adata_bin.n_obs,\n",
    "            'runtime': runtime\n",
    "        }\n",
    "    \n",
    "    return results, cell_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Resolution Horizon Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_resolution_metrics(results, cell_types):\n",
    "    \"\"\"\n",
    "    Compute metrics that reveal the resolution horizon.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    metrics : DataFrame\n",
    "        Metrics for each bin size\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for bin_size, data in results.items():\n",
    "        props = data['proportions']\n",
    "        \n",
    "        # 1. Signal purity: fraction of spots with >80% dominant cell type\n",
    "        max_props = props.max(axis=1)\n",
    "        purity = (max_props > 0.8).mean()\n",
    "        \n",
    "        # 2. Mixing entropy: average Shannon entropy across spots\n",
    "        props_safe = np.clip(props, 1e-10, 1)\n",
    "        spot_entropy = entropy(props_safe, axis=1, base=2)\n",
    "        max_entropy = np.log2(props.shape[1])  # Normalize\n",
    "        mean_entropy = spot_entropy.mean() / max_entropy\n",
    "        \n",
    "        # 3. Effective cell types per spot\n",
    "        effective_k = np.exp(entropy(props_safe, axis=1)).mean()\n",
    "        \n",
    "        # 4. Per-cell-type max proportion (can we still detect each type?)\n",
    "        ct_max = {ct: props[:, i].max() for i, ct in enumerate(cell_types)}\n",
    "        \n",
    "        records.append({\n",
    "            'bin_size': bin_size,\n",
    "            'n_spots': data['n_spots'],\n",
    "            'runtime': data['runtime'],\n",
    "            'purity': purity,\n",
    "            'entropy': mean_entropy,\n",
    "            'effective_k': effective_k,\n",
    "            **{f'max_{ct}': v for ct, v in ct_max.items()}\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(records).sort_values('bin_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resolution_horizon(metrics, cell_types, highlight_types=None):\n",
    "    \"\"\"\n",
    "    Create publication-ready resolution horizon figure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics : DataFrame\n",
    "        Output from compute_resolution_metrics\n",
    "    cell_types : list\n",
    "        Cell type names\n",
    "    highlight_types : list, optional\n",
    "        Cell types to highlight (e.g., rare types)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 3.5))\n",
    "    \n",
    "    bin_sizes = metrics['bin_size'].values\n",
    "    x = np.arange(len(bin_sizes))\n",
    "    \n",
    "    # Panel A: Signal purity collapse\n",
    "    ax = axes[0]\n",
    "    purity = metrics['purity'].values * 100\n",
    "    bars = ax.bar(x, purity, color='#2ecc71', edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Highlight the \"cliff\"\n",
    "    if len(purity) > 1:\n",
    "        drop = purity[0] - purity[1]\n",
    "        if drop > 20:\n",
    "            ax.annotate(f'-{drop:.0f}%', xy=(0.5, purity[1] + drop/2),\n",
    "                       fontsize=9, ha='center', color='red', weight='bold')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{b}\u03bcm' for b in bin_sizes])\n",
    "    ax.set_ylabel('Pure spots (>80% dominant type) [%]')\n",
    "    ax.set_xlabel('Bin size')\n",
    "    ax.set_title('A. Signal Purity', fontweight='bold', loc='left')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.axhline(50, ls='--', color='gray', lw=0.8, alpha=0.5)\n",
    "    \n",
    "    # Panel B: Mixing entropy\n",
    "    ax = axes[1]\n",
    "    ent = metrics['entropy'].values\n",
    "    ax.plot(x, ent, 'o-', color='#e74c3c', lw=2, markersize=8)\n",
    "    ax.fill_between(x, 0, ent, alpha=0.2, color='#e74c3c')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{b}\u03bcm' for b in bin_sizes])\n",
    "    ax.set_ylabel('Normalized mixing entropy')\n",
    "    ax.set_xlabel('Bin size')\n",
    "    ax.set_title('B. Signal Mixing', fontweight='bold', loc='left')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Panel C: Cell type detectability\n",
    "    ax = axes[2]\n",
    "    cmap = plt.cm.tab10\n",
    "    \n",
    "    for i, ct in enumerate(cell_types):\n",
    "        col = f'max_{ct}'\n",
    "        if col in metrics.columns:\n",
    "            vals = metrics[col].values * 100\n",
    "            style = '-' if highlight_types and ct in highlight_types else '--'\n",
    "            lw = 2 if highlight_types and ct in highlight_types else 1\n",
    "            alpha = 1.0 if highlight_types and ct in highlight_types else 0.5\n",
    "            ax.plot(x, vals, style, color=cmap(i % 10), lw=lw, alpha=alpha,\n",
    "                   label=ct, marker='o', markersize=4)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{b}\u03bcm' for b in bin_sizes])\n",
    "    ax.set_ylabel('Max detectable proportion [%]')\n",
    "    ax.set_xlabel('Bin size')\n",
    "    ax.set_title('C. Cell Type Detectability', fontweight='bold', loc='left')\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=7)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.axhline(10, ls=':', color='gray', lw=0.8, alpha=0.5)\n",
    "    ax.text(len(x)-0.5, 12, 'detection limit', fontsize=7, color='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Run Analysis\n",
    "\n",
    "Execute the multi-resolution analysis on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading Visium HD data...\")\n",
    "adata_st = load_visium_hd(VISIUM_HD_DIR, bin_size=\"008um\")  # Start from 8\u03bcm\n",
    "print(f\"Spatial data: {adata_st.n_obs:,} spots, {adata_st.n_vars:,} genes\")\n",
    "\n",
    "print(\"\\nLoading reference data...\")\n",
    "adata_ref = sc.read_h5ad(REFERENCE_PATH)\n",
    "print(f\"Reference: {adata_ref.n_obs:,} cells, {adata_ref.n_vars:,} genes\")\n",
    "print(f\"Cell types: {adata_ref.obs[CELL_TYPE_KEY].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multi-resolution analysis\n",
    "results, cell_types = run_multiscale_analysis(\n",
    "    adata_st, \n",
    "    adata_ref, \n",
    "    cell_type_key=CELL_TYPE_KEY,\n",
    "    bin_sizes=[8, 16, 32, 64, 128],  # Adjust based on your data\n",
    "    base_um=8\n",
    ")\n",
    "\n",
    "print(f\"\\nCell types: {cell_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute resolution metrics\n",
    "metrics = compute_resolution_metrics(results, cell_types)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESOLUTION HORIZON ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(metrics[['bin_size', 'n_spots', 'runtime', 'purity', 'entropy', 'effective_k']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# Specify rare cell types to highlight (adjust for your data)\n",
    "rare_types = [ct for ct in cell_types if 'stem' in ct.lower() or 'tuft' in ct.lower()]\n",
    "\n",
    "fig = plot_resolution_horizon(metrics, cell_types, highlight_types=rare_types)\n",
    "fig.savefig('resolution_horizon.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_findings(metrics, cell_types):\n",
    "    \"\"\"Print key findings from the resolution analysis.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KEY FINDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Resolution horizon\n",
    "    purity = metrics['purity'].values\n",
    "    bin_sizes = metrics['bin_size'].values\n",
    "    \n",
    "    # Find where purity drops below 50%\n",
    "    horizon_idx = np.where(purity < 0.5)[0]\n",
    "    if len(horizon_idx) > 0:\n",
    "        horizon = bin_sizes[horizon_idx[0]]\n",
    "        print(f\"\\n1. RESOLUTION HORIZON: {bin_sizes[horizon_idx[0]-1]}\u03bcm \u2192 {horizon}\u03bcm\")\n",
    "        print(f\"   Purity drops below 50% at {horizon}\u03bcm\")\n",
    "    \n",
    "    # 2. Information loss\n",
    "    if len(purity) > 1:\n",
    "        loss = (purity[0] - purity[1]) / purity[0] * 100\n",
    "        print(f\"\\n2. INFORMATION LOSS: {loss:.0f}% from {bin_sizes[0]}\u03bcm to {bin_sizes[1]}\u03bcm\")\n",
    "    \n",
    "    # 3. Cell type resolution requirements\n",
    "    print(f\"\\n3. CELL TYPE RESOLUTION SENSITIVITY:\")\n",
    "    for ct in cell_types:\n",
    "        col = f'max_{ct}'\n",
    "        if col in metrics.columns:\n",
    "            vals = metrics[col].values\n",
    "            # Find smallest bin size where max prop > 10%\n",
    "            detectable = bin_sizes[vals > 0.1]\n",
    "            if len(detectable) > 0:\n",
    "                loss_pct = (vals[0] - vals[-1]) / vals[0] * 100 if vals[0] > 0 else 0\n",
    "                status = \"\u26a0\ufe0f SENSITIVE\" if loss_pct > 50 else \"\u2713 robust\"\n",
    "                print(f\"   {ct:20s}: {loss_pct:5.0f}% signal loss  {status}\")\n",
    "    \n",
    "    # 4. Recommendations\n",
    "    print(f\"\\n4. RECOMMENDATIONS:\")\n",
    "    finest = bin_sizes[0]\n",
    "    print(f\"   \u2022 For rare cell types: use \u2264{finest}\u03bcm resolution\")\n",
    "    print(f\"   \u2022 For abundant cell types: {bin_sizes[min(2, len(bin_sizes)-1)]}\u03bcm may suffice\")\n",
    "    print(f\"   \u2022 Always run multi-scale analysis to validate findings\")\n",
    "\n",
    "summarize_findings(metrics, cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Adapting to Your Own Data\n",
    "\n",
    "To use this analysis with your own Visium HD dataset:\n",
    "\n",
    "1. **Prepare your spatial data**: Load as AnnData with coordinates in `.obsm['spatial']`\n",
    "\n",
    "2. **Prepare your reference**: scRNA-seq AnnData with cell type labels in `.obs`\n",
    "\n",
    "3. **Modify the config**:\n",
    "```python\n",
    "VISIUM_HD_DIR = Path(\"/path/to/your/visium_hd_outputs\")\n",
    "REFERENCE_PATH = Path(\"/path/to/your/reference.h5ad\")\n",
    "CELL_TYPE_KEY = \"your_celltype_column\"\n",
    "```\n",
    "\n",
    "4. **Adjust bin sizes** based on your platform:\n",
    "   - Visium HD: `[8, 16, 32, 64, 128]`\n",
    "   - Standard Visium: `[55, 110, 220]` (55\u03bcm native resolution)\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- FlashDeconv: https://github.com/cafferychen777/flashdeconv\n",
    "- 10x Genomics Visium HD: https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression\n",
    "- Haber et al. (2017). A single-cell survey of the small intestinal epithelium. *Nature*, 551, 333-339."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}